{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In Python: Define a database name, and your username for your computer. \n",
    "dbname = 'oped_db'\n",
    "username = 'varun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://varun@localhost/oped_db\n"
     ]
    }
   ],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print engine.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load a database from CSV\n",
    "dataall = pd.DataFrame.from_csv('dataall.csv')\n",
    "datadate = pd.DataFrame.from_csv('datadate.csv')\n",
    "topicweights = pd.DataFrame.from_csv('topicweights{0}.csv'.format(n_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "## df is any pandas dataframe \n",
    "dataall.to_sql('orig', engine, if_exists='replace')\n",
    "datadate.to_sql('dates_and_tidy', engine, if_exists='replace')\n",
    "topicweights.to_sql('topic_weights', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now try the same queries, but in python!\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.348150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0.364297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>0.337865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>0.279798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287</td>\n",
       "      <td>0.470296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    topic0\n",
       "0      4  0.348150\n",
       "1     34  0.364297\n",
       "2    141  0.337865\n",
       "3    281  0.279798\n",
       "4    287  0.470296"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT topic_weights.index, topic_weights.topic0 FROM topic_weights\n",
    "WHERE topic0 > 0.2;\n",
    "\"\"\"\n",
    "data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query:\n",
    "def query_for_person(firstname,lastname):\n",
    "    return \"\"\"\n",
    "    SELECT orig.share_count, topic_weights.*\n",
    "    FROM orig\n",
    "        JOIN topic_weights\n",
    "            ON orig.index = topic_weights.index\n",
    "    WHERE orig.first_name='{0}' AND orig.last_name='{1}';\n",
    "    \"\"\".format(firstname,lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share_count</th>\n",
       "      <th>index</th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>...</th>\n",
       "      <th>topic40</th>\n",
       "      <th>topic41</th>\n",
       "      <th>topic42</th>\n",
       "      <th>topic43</th>\n",
       "      <th>topic44</th>\n",
       "      <th>topic45</th>\n",
       "      <th>topic46</th>\n",
       "      <th>topic47</th>\n",
       "      <th>topic48</th>\n",
       "      <th>topic49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>818</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.225027</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.043902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>790</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.020271</td>\n",
       "      <td>0.044775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4503</td>\n",
       "      <td>152</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.024821</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024696</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.073259</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.067449</td>\n",
       "      <td>0.201081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1590</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.068667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6806</td>\n",
       "      <td>202</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.023220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.122524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   share_count  index    topic0    topic1    topic2    topic3    topic4  \\\n",
       "0          818     38  0.000061  0.000061  0.000061  0.000061  0.000061   \n",
       "1          790     72  0.000067  0.000067  0.000067  0.000067  0.000067   \n",
       "2         4503    152  0.000064  0.024821  0.000064  0.000064  0.000064   \n",
       "3         1590    121  0.000064  0.000064  0.045788  0.000064  0.000064   \n",
       "4         6806    202  0.000068  0.000068  0.000068  0.000068  0.000068   \n",
       "\n",
       "     topic5    topic6    topic7    ...      topic40   topic41   topic42  \\\n",
       "0  0.225027  0.000061  0.055129    ...     0.000061  0.000061  0.000061   \n",
       "1  0.000067  0.000067  0.000067    ...     0.000067  0.000067  0.000067   \n",
       "2  0.000064  0.000064  0.000064    ...     0.024696  0.000064  0.000064   \n",
       "3  0.000064  0.000064  0.000064    ...     0.000064  0.000064  0.000064   \n",
       "4  0.000068  0.000068  0.023220    ...     0.000068  0.000068  0.000068   \n",
       "\n",
       "    topic43   topic44   topic45   topic46   topic47   topic48   topic49  \n",
       "0  0.000061  0.000061  0.000061  0.000061  0.000061  0.000061  0.043902  \n",
       "1  0.000067  0.000067  0.000067  0.000067  0.020350  0.020271  0.044775  \n",
       "2  0.000064  0.000064  0.073259  0.000064  0.000064  0.067449  0.201081  \n",
       "3  0.000064  0.000064  0.000064  0.000064  0.035754  0.000064  0.068667  \n",
       "4  0.000068  0.000068  0.000068  0.000068  0.000068  0.000068  0.122524  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = query_for_person('paul','krugman')\n",
    "data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_from_sql['log_share_count'] = np.log10(data_from_sql['share_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmin = np.min(data_from_sql['log_share_count'])\n",
    "xmax = np.max(data_from_sql['log_share_count'])\n",
    "bins = np.linspace(xmin,xmax,10)\n",
    "binnum = np.digitize(data_from_sql['log_share_count'],bins)\n",
    "binnum[binnum <= 5] = 0\n",
    "binnum[binnum > 5] = 1\n",
    "data_from_sql['bin_share_count'] = binnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data_from_sql['log_share_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_topics = 50\n",
    "featurenames = ['topic{0}'.format(i) for i in range(n_topics)]\n",
    "features = data_from_sql[featurenames]\n",
    "viralityname = 'log_share_count'\n",
    "virality = data_from_sql[viralityname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data,frac=0.7):\n",
    "    datanew = data.sample(frac=1)\n",
    "    nrows = len(datanew)\n",
    "    idx = int(nrows*frac)\n",
    "    return {'train': datanew.iloc[:idx], 'test': datanew.iloc[idx:]}\n",
    "    # use 70-30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(split_data,model,errorfun,**kwargs):\n",
    "    datatrain = split_data['train']\n",
    "    datatest = split_data['test']\n",
    "    model.fit(datatrain[featurenames],datatrain[viralityname],**kwargs)\n",
    "    train_pred = model.predict(datatrain[featurenames])\n",
    "    test_pred = model.predict(datatest[featurenames])\n",
    "    train_error = errorfun(train_pred,datatrain[viralityname])\n",
    "    test_error = errorfun(test_pred,datatest[viralityname])\n",
    "    print('Training error: {0}'.format(train_error))\n",
    "    print('Test error: {0}'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasplit = split_data(data_from_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_error_class(predicted,actual):\n",
    "    nobs = actual.size\n",
    "    return 1.0/nobs*np.sum((actual - predicted)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "ax = fig.gca()\n",
    "ax = ax.matshow(data_from_sql[featurenames], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(datatrain[featurenames],datatrain['bin_share_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighbors(n_neighbors=i)\n",
    "train_model(datasplit,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_error_regr(predicted,actual):\n",
    "    nobs = actual.size\n",
    "    return np.sqrt(1.0/(2.0*nobs)*np.sum((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coeff_regr(predicted,actual):\n",
    "    avg = np.mean(actual)\n",
    "    sstot = np.sum((actual - avg)**2)\n",
    "    ssres = np.sum((actual - predicted)**2)\n",
    "    return 1 - ssres/sstot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.438524378017\n",
      "Test error: -4.37725989263\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = data_from_sql[viralityname]\n",
    "pred = model.predict(data_from_sql[featurenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(actual,pred,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsRegressor(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.0930888034172\n",
      "Test error: 0.182169596621\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = data_from_sql[viralityname]\n",
    "pred = model.predict(data_from_sql[featurenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(actual,pred,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.123736648092\n",
      "Test error: 0.159580338504\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(dataallnew[viralityname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 1.0\n",
      "Test error: -1.57570050605\n",
      "Training error: 0.486015701869\n",
      "Test error: -0.498145944473\n",
      "Training error: 0.376983043397\n",
      "Test error: -0.515264379594\n",
      "Training error: 0.313442065944\n",
      "Test error: -0.503127637623\n",
      "Training error: 0.30653086839\n",
      "Test error: -0.462875305515\n",
      "Training error: 0.314335191992\n",
      "Test error: -0.344951428193\n",
      "Training error: 0.306781189054\n",
      "Test error: -0.386864302163\n",
      "Training error: 0.262677780013\n",
      "Test error: -0.250925258364\n",
      "Training error: 0.250909172593\n",
      "Test error: -0.212311465435\n",
      "Training error: 0.242121230302\n",
      "Test error: -0.140216610601\n",
      "Training error: 0.235558480477\n",
      "Test error: -0.150352326529\n",
      "Training error: 0.225711968947\n",
      "Test error: -0.0702849199616\n",
      "Training error: 0.234862458749\n",
      "Test error: -0.0463540656595\n",
      "Training error: 0.229635379158\n",
      "Test error: -0.0525599811083\n",
      "Training error: 0.240268764203\n",
      "Test error: -0.0395068259081\n",
      "Training error: 0.240871267392\n",
      "Test error: -0.0299143932902\n",
      "Training error: 0.24218076312\n",
      "Test error: -0.0118178267174\n",
      "Training error: 0.219969558831\n",
      "Test error: -0.0152928957453\n",
      "Training error: 0.225619581387\n",
      "Test error: 0.0286800038024\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors=i)\n",
    "    train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load a database from CSV\n",
    "dataall = pd.DataFrame.from_csv('dataall.csv')\n",
    "datadate = pd.DataFrame.from_csv('datadate.csv')\n",
    "dataauthor = pd.DataFrame.from_csv('dataauthor.csv')\n",
    "dataother = pd.DataFrame.from_csv('dataother.csv')\n",
    "topicweights10 = pd.DataFrame.from_csv('topicweights10.csv')\n",
    "topicweights50 = pd.DataFrame.from_csv('topicweights_2_50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 50\n",
    "n_authors = 38\n",
    "n_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In Python: Define a database name, and your username for your computer. \n",
    "dbname = 'oped_db'\n",
    "username = 'varun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://varun@localhost/oped_db\n"
     ]
    }
   ],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print engine.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "## df is any pandas dataframe \n",
    "dataall.to_sql('orig', engine, if_exists='replace')\n",
    "datadate.to_sql('dates', engine, if_exists='replace')\n",
    "dataauthor.to_sql('authors', engine, if_exists='replace')\n",
    "dataother.to_sql('other', engine, if_exists='replace')\n",
    "topicweights10.to_sql('topic_weights10', engine, if_exists='replace')\n",
    "topicweights50.to_sql('topic_weights50', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now try the same queries, but in python!\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query:\n",
    "def query_for_person(firstname,lastname):\n",
    "    return \"\"\"\n",
    "    SELECT orig.share_count, topic_weights.*\n",
    "    FROM orig\n",
    "        JOIN topic_weights\n",
    "            ON orig.index = topic_weights.index\n",
    "    WHERE orig.first_name='{0}' AND orig.last_name='{1}';\n",
    "    \"\"\".format(firstname,lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share_count</th>\n",
       "      <th>index</th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>665</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.106056</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.093017</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.904957</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412</td>\n",
       "      <td>135</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.092126</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>0.083471</td>\n",
       "      <td>0.156396</td>\n",
       "      <td>0.616574</td>\n",
       "      <td>0.020025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.071105</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.098962</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.820691</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3061</td>\n",
       "      <td>215</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.044130</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.081990</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.738386</td>\n",
       "      <td>0.107473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   share_count  index    topic0    topic1    topic2    topic3    topic4  \\\n",
       "0          665     53  0.000372  0.000372  0.000372  0.000372  0.106056   \n",
       "1          305     85  0.000253  0.000253  0.093017  0.000253  0.000253   \n",
       "2          412    135  0.000343  0.000343  0.000343  0.000343  0.092126   \n",
       "3          296    177  0.000262  0.000262  0.071105  0.007671  0.000262   \n",
       "4         3061    215  0.000339  0.000339  0.000339  0.044130  0.026326   \n",
       "\n",
       "     topic5    topic6    topic7    topic8    topic9  \n",
       "0  0.000372  0.000372  0.000372  0.890969  0.000372  \n",
       "1  0.000253  0.000253  0.000253  0.904957  0.000253  \n",
       "2  0.030038  0.083471  0.156396  0.616574  0.020025  \n",
       "3  0.000262  0.098962  0.000262  0.820691  0.000262  \n",
       "4  0.081990  0.000339  0.000339  0.738386  0.107473  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = query_for_person('ross','douthat')\n",
    "data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query:\n",
    "def query_all():\n",
    "    return \"\"\"\n",
    "    SELECT orig.share_count, topic_weights50.*, authors.*, dates.*\n",
    "    FROM orig\n",
    "        JOIN topic_weights50\n",
    "            ON orig.index = topic_weights50.index\n",
    "        JOIN authors\n",
    "            ON orig.index = authors.index\n",
    "        JOIN dates\n",
    "            ON orig.index = dates.index\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share_count</th>\n",
       "      <th>index</th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>...</th>\n",
       "      <th>index</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Times</th>\n",
       "      <th>Day0</th>\n",
       "      <th>Day1</th>\n",
       "      <th>Day2</th>\n",
       "      <th>Day3</th>\n",
       "      <th>Day4</th>\n",
       "      <th>Day5</th>\n",
       "      <th>Day6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6308</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.154154</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.177759</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>685</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.225319</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.373768</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040</td>\n",
       "      <td>4</td>\n",
       "      <td>0.288671</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.106781</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   share_count  index    topic0    topic1    topic2    topic3    topic4  \\\n",
       "0         1502      0  0.000059  0.000059  0.000059  0.000059  0.014383   \n",
       "1         6308      1  0.012066  0.000043  0.000043  0.000043  0.005877   \n",
       "2          826      2  0.000044  0.000044  0.013690  0.000044  0.018525   \n",
       "3          685      3  0.000070  0.225319  0.000070  0.000070  0.000070   \n",
       "4         1040      4  0.288671  0.000066  0.000066  0.000066  0.007971   \n",
       "\n",
       "     topic5    topic6    topic7  ...   index       Dates  Times  Day0  Day1  \\\n",
       "0  0.000059  0.000059  0.000059  ...       0  2016-03-31    1.0   0.0   0.0   \n",
       "1  0.000043  0.000043  0.154154  ...       1  2016-03-31    1.0   0.0   0.0   \n",
       "2  0.000044  0.000044  0.177759  ...       2  2016-03-31    1.0   0.0   0.0   \n",
       "3  0.014989  0.000070  0.373768  ...       3  2016-03-31    1.0   0.0   0.0   \n",
       "4  0.000066  0.106781  0.000066  ...       4  2016-03-31    1.0   0.0   0.0   \n",
       "\n",
       "   Day2  Day3  Day4  Day5  Day6  \n",
       "0   0.0   1.0   0.0   0.0   0.0  \n",
       "1   0.0   1.0   0.0   0.0   0.0  \n",
       "2   0.0   1.0   0.0   0.0   0.0  \n",
       "3   0.0   1.0   0.0   0.0   0.0  \n",
       "4   0.0   1.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = query_all()\n",
    "data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_from_sql['log_share_count'] = np.log10(data_from_sql['share_count'])\n",
    "data_from_sql[data_from_sql['log_share_count'] < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmin = np.min(data_from_sql['log_share_count'])\n",
    "xmax = np.max(data_from_sql['log_share_count'])\n",
    "bins = np.linspace(xmin,xmax,10)\n",
    "binnum = np.digitize(data_from_sql['log_share_count'],bins)\n",
    "binnum[binnum <= 5] = 0\n",
    "binnum[binnum > 5] = 1\n",
    "data_from_sql['bin_share_count'] = binnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data_from_sql['log_share_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<type 'float'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.fit(np.array([[1],[2],[3],[5],[6],[7],[2],[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.transform(np.array([[2],[3],[2]])).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, neighbors, ensemble, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data,frac=0.7):\n",
    "    datanew = data.sample(frac=1)\n",
    "    nrows = len(datanew)\n",
    "    idx = int(nrows*frac)\n",
    "    return {'train': datanew.iloc[:idx], 'test': datanew.iloc[idx:]}\n",
    "    # use 70-30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(split_data,model,errorfun,**kwargs):\n",
    "    datatrain = split_data['train']\n",
    "    datatest = split_data['test']\n",
    "    model.fit(datatrain[featurenames],datatrain[viralityname],**kwargs)\n",
    "    train_pred = model.predict(datatrain[featurenames])\n",
    "    test_pred = model.predict(datatest[featurenames])\n",
    "    train_error = errorfun(train_pred,datatrain[viralityname])\n",
    "    test_error = errorfun(test_pred,datatest[viralityname])\n",
    "    print('Training error: {0}'.format(train_error))\n",
    "    print('Test error: {0}'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topicnames = ['topic{0}'.format(i) for i in range(n_topics)]\n",
    "authornames = ['author{0}'.format(i) for i in range(n_authors)]\n",
    "daynames = ['Day{0}'.format(i) for i in range(n_days)]\n",
    "# othernames = ['len','Times']\n",
    "# othernames = ['Times']\n",
    "othernames = []\n",
    "featurenames = topicnames + authornames + daynames + othernames\n",
    "features = data_from_sql[featurenames]\n",
    "viralityname = 'log_share_count'\n",
    "virality = data_from_sql[viralityname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasplit = split_data(data_from_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_error_class(predicted,actual):\n",
    "    nobs = actual.size\n",
    "    return 1.0/nobs*np.sum((actual - predicted)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "ax = fig.gca()\n",
    "ax = ax.matshow(data_from_sql[featurenames], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(datatrain[featurenames],datatrain['bin_share_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighbors(n_neighbors=i)\n",
    "train_model(datasplit,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_error_regr(predicted,actual):\n",
    "    nobs = actual.size\n",
    "    return np.sqrt(1.0/(2.0*nobs)*np.sum((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coeff_regr(predicted,actual):\n",
    "    avg = np.mean(actual)\n",
    "    sstot = np.sum((actual - avg)**2)\n",
    "    ssres = np.sum((actual - predicted)**2)\n",
    "    return 1 - ssres/sstot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.Ridge(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_from_sql[featurenames],data_from_sql[viralityname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.393160838817\n",
      "Test error: 0.380005421563\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for featurename, coef in zip(featurenames, model.coef_):\n",
    "    # print(featurename, coef)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsRegressor(n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.187695875874\n",
      "Test error: 0.164337671611\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestRegressor(n_estimators=50,max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.912122608486\n",
      "Test error: 0.416150523842\n"
     ]
    }
   ],
   "source": [
    "train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ridge' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-dadadd207663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturenames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# print(feature, importance)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ridge' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "for feature, importance in zip(featurenames,model.feature_importances_):\n",
    "    # print(feature, importance)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.998883446246\n",
      "Test error: -0.147600334939\n",
      "Training error: 0.716377900879\n",
      "Test error: 0.152592380258\n",
      "Training error: 0.619053854171\n",
      "Test error: 0.243409621316\n",
      "Training error: 0.569168974685\n",
      "Test error: 0.290740795355\n",
      "Training error: 0.535852162635\n",
      "Test error: 0.314018356802\n",
      "Training error: 0.515676841609\n",
      "Test error: 0.328033807347\n",
      "Training error: 0.500432695738\n",
      "Test error: 0.332794871677\n",
      "Training error: 0.488118540344\n",
      "Test error: 0.34068243082\n",
      "Training error: 0.478990621509\n",
      "Test error: 0.345101970322\n",
      "Training error: 0.469109110887\n",
      "Test error: 0.344840873636\n",
      "Training error: 0.461235157144\n",
      "Test error: 0.34593098155\n",
      "Training error: 0.454972515161\n",
      "Test error: 0.350557689176\n",
      "Training error: 0.448723296798\n",
      "Test error: 0.351332730917\n",
      "Training error: 0.444368263776\n",
      "Test error: 0.353331101435\n",
      "Training error: 0.439076912761\n",
      "Test error: 0.355747969173\n",
      "Training error: 0.437369664485\n",
      "Test error: 0.355988512055\n",
      "Training error: 0.43284801782\n",
      "Test error: 0.352899477027\n",
      "Training error: 0.429192621953\n",
      "Test error: 0.35384234248\n",
      "Training error: 0.424704593041\n",
      "Test error: 0.353192479167\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors=i)\n",
    "    train_model(datasplit,model,coeff_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickleizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleizer.save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make Some Predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import model_predict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorid = model_predict.AUTHORID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in authorid.keys():\n",
    "    if type(key[0]) != str:\n",
    "        ans = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.isnan(ans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.nytimes.com/2016/06/03/opinion/the-id-that-ate-the-planet.html'\n",
    "firstname = 'nicholas'\n",
    "lastname = 'kristof'\n",
    "dayofweek = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict.predict_new_article_url(firstname,lastname,dayofweek,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NYTIMESAPIKEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-0db8b8039c29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NYTIMESAPIKEY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/varun/anaconda2/lib/python2.7/UserDict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__missing__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NYTIMESAPIKEY'"
     ]
    }
   ],
   "source": [
    "os.environ['NYTIMESAPIKEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of nytimes_crawl_2 failed: Traceback (most recent call last):\n",
      "  File \"/home/varun/anaconda2/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "KeyError: 'NYTIMESAPIKEY'\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AUTHORID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-19107e65ee02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUTHORID\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'AUTHORID' is not defined"
     ]
    }
   ],
   "source": [
    "AUTHORID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
